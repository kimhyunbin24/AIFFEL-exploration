- 미니배치를 사용하는 이유: sgd와 full batch의 중간정도 되는 방법으로써 두가지 단점을 보완하는 방법이다
- 데이터가 불균형일때에 균형을 맞추어주는것이 필요하다. 
- data augmentation 만을 추가하였더니 기존의 결과에서 정확도가 10%정도 높아졌고 루브릭 기준을 맞추기위해서 모델 레이어를 수정하였다.
- 역시 딥러닝에서는 DATA의 양과 질이 중요한것같다.
