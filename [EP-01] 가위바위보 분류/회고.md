# AIFFEL-exploration-01 가위바위보 분류 회고

처음 모델을 만들고 결과를 보았을때 40%대의 정확도를 보였고 사람이봐도 더쉽게 알수있는 데이터를 썻더니 결과값이 조금 더 좋게나왔다
데이터의 양과 질이 굉장히 중요하다는것을 깨달았다

## 1. 데이터 업로드 및 리사이즈
	def resize_images(img_path):
		images=glob.glob(img_path + "/*.jpg")  
    
	print(len(images), " images to be resized.")

    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.
	target_size=(28,28)
	for img in images:
		old_img=Image.open(img)
		new_img=old_img.resize(target_size,Image.ANTIALIAS)
		new_img.save(img, "JPEG")
    
	print(len(images), " images resized.")
	

	image_dir_path = os.getenv("HOME") + "/aiffel/rock_scissor_paper/scissor"
	resize_images(image_dir_path)

224 x 224 의 이미지를 28 x 28 로 줄여줌으로써 사이즈 통일

## 1.2 데이터 라벨링 및 정규화

	def load_data(img_path, number_of_data=1812):  # 데이터 갯수 총합
    	# 가위 : 0, 바위 : 1, 보 : 2
    	img_size=28
    	color=3
    	imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)
    	labels=np.zeros(number_of_data,dtype=np.int32)

    idx=0
    for file in glob.iglob(img_path+'/scissor/*.jpg'):
        img = np.array(Image.open(file),dtype=np.int32)
        imgs[idx,:,:,:]=img    
        labels[idx]=0   # 가위 : 0
        idx=idx+1

    for file in glob.iglob(img_path+'/rock/*.jpg'):
        img = np.array(Image.open(file),dtype=np.int32)
        imgs[idx,:,:,:]=img   
        labels[idx]=1   # 바위 : 1
        idx=idx+1  
    
    for file in glob.iglob(img_path+'/paper/*.jpg'):
        img = np.array(Image.open(file),dtype=np.int32)
        imgs[idx,:,:,:]=img    
        labels[idx]=2   # 보 : 2
        idx=idx+1
        
    print("학습데이터(x_train)의 이미지 개수는", idx,"입니다.")
    return imgs, labels

	image_dir_path = os.getenv("HOME") + "/aiffel/rock_scissor_paper"
	(x_train, y_train)=load_data(image_dir_path)
	x_train_norm = x_train/255.0   # 입력값을 0~1사이로 정규화 해줌

	print("x_train shape: {}".format(x_train.shape)) # (데이터갯수, 이미지 x축크기, 이미지 y축크기, 채널수=분류하고자하는 클래스의 갯수)
	print("y_train shape: {}".format(y_train.shape))
정규화


## 2. 모델만들기

	model=keras.models.Sequential()
	model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3))) # 3채널
	model.add(keras.layers.MaxPool2D(2,2))
	model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))
	model.add(keras.layers.MaxPooling2D((2,2)))
	model.add(keras.layers.Flatten())
	model.add(keras.layers.Dense(32, activation='relu'))
	model.add(keras.layers.Dense(3, activation='softmax')) # 최종분류의 클래스가 3개이기때문에 3

	print('Model에 추가된 Layer 개수: ', len(model.layers))

	model.summary()

## 2.2 네트워크 설정
	print("Before Reshape - x_train_norm shape: {}".format(x_train_norm.shape))
	x_train_reshaped=x_train_norm.reshape( -1, 28, 28, 3)  # (데이터갯수, 이미지 크기 x, 이미지 크기 y, 채널수) 분류의 클래스가 3개이기때문에 3채널
	print("After Reshape - x_train_reshaped shape: {}".format(x_train_reshaped.shape))

x_train_reshaped=x_train_norm.reshape( -1, 28, 28, 3) = (데이터갯수, 이미지 크기 x, 이미지 크기 y, 채널수)
## 3. 학습
	model.compile(optimizer='adam',
		     loss='sparse_categorical_crossentropy',
		     metrics=['accuracy'])

	model.fit(x_train_reshaped, y_train, epochs=10) # 10회 학습
	
## 4. 테스트셋으로 모델 평가하기
	test_loss, test_accuracy = model.evaluate(x_test_reshaped,y_test, verbose=2)
	print("test_loss: {} ".format(test_loss))
	print("test_accuracy: {}".format(test_accuracy))
	
	10/10 - 0s - loss: 4.2988 - accuracy: 0.4983
	test_loss: 4.298758506774902 
	test_accuracy: 0.498305082321167
테스트셋의 평가가 너무 낮게나와 다른데이터로 시도도해보았지만 과적합이 발생하는등 여러 문제가 생겼다.
